# üì° TelecomX ‚Äì Predicci√≥n de Cancelaci√≥n de Clientes (Churn)

> **Challenge de Ciencia de Datos | Parte 1 + Parte 2**  
> An√°lisis exploratorio, modelado predictivo y estrategias de retenci√≥n para una empresa de telecomunicaciones.

---

## üìã Descripci√≥n del Proyecto

Este proyecto forma parte del **Challenge TelecomX** de Alura LATAM, desarrollado en dos etapas:

- **Parte 1:** An√°lisis Exploratorio de Datos (EDA) ‚Äî entender el comportamiento hist√≥rico del churn.
- **Parte 2:** Modelado Predictivo con Machine Learning ‚Äî construir modelos capaces de anticipar qu√© clientes tienen mayor riesgo de cancelar sus servicios.

El objetivo final es proporcionar a TelecomX una herramienta basada en datos que le permita **anticiparse a la p√©rdida de clientes** e implementar estrategias de retenci√≥n personalizadas.

---

## üìÅ Estructura del Repositorio

```
telecomx-churn/
‚îÇ
‚îú‚îÄ‚îÄ TelecomX_LATAM.ipynb          # Parte 1: EDA y an√°lisis exploratorio
‚îú‚îÄ‚îÄ TelecomX_Parte2_ML.ipynb      # Parte 2: Modelado predictivo con ML
‚îî‚îÄ‚îÄ README.md                     # Este archivo
```

---

## üóÇÔ∏è Dataset

- **Fuente:** [TelecomX Data ‚Äì GitHub Alura LATAM](https://raw.githubusercontent.com/ingridcristh/challenge2-data-science-LATAM/main/TelecomX_Data.json)
- **Formato:** JSON con columnas anidadas (customer, phone, internet, account)
- **Tama√±o:** 7,267 clientes | 29 variables tras el desempaquetado
- **Variable objetivo:** `Churn` (1 = cancel√≥, 0 = activo)
- **Churn rate base:** 25.72%

---

## üîç Parte 1 ‚Äî An√°lisis Exploratorio de Datos (EDA)

### Proceso

**Extracci√≥n y Transformaci√≥n**
- Carga del JSON desde la API de GitHub
- Desempaquetado de columnas anidadas (`customer`, `phone`, `internet`, `account`)
- Conversi√≥n de tipos de datos (`TotalCharges` a num√©rico)
- Tratamiento de valores nulos y duplicados
- Estandarizaci√≥n de la variable `Churn` (Yes/No ‚Üí 1/0)

**An√°lisis Realizado**
- Distribuci√≥n general del churn (25.72% de cancelaciones)
- An√°lisis demogr√°fico: g√©nero, adultos mayores, pareja, dependientes
- An√°lisis de servicios: tipo de internet, l√≠neas telef√≥nicas, servicios adicionales
- An√°lisis de contrato: tipo, m√©todo de pago, facturaci√≥n electr√≥nica
- An√°lisis temporal: tenure (meses de contrato) y su relaci√≥n con el churn
- Correlaci√≥n entre variables num√©ricas y la cancelaci√≥n

### Principales Hallazgos

| Factor | Churn Rate | Insight |
|--------|-----------|---------|
| Primeros 6 meses de contrato | 51.41% | Per√≠odo cr√≠tico de fuga |
| Contrato Month-to-month | 41.32% | Sin compromiso = mayor riesgo |
| Pago con Electronic Check | 43.80% | M√©todo manual = menor lealtad |
| Internet Fiber Optic | 40.56% | Problemas de satisfacci√≥n |
| Senior Citizens | 40.27% | Grupo vulnerable |
| Contrato Two-year | 2.75% | Mayor retenci√≥n |
| 4+ a√±os de contrato | 9.22% | Lealtad consolidada |

---

## ü§ñ Parte 2 ‚Äî Modelado Predictivo (Machine Learning)

### a) Preparaci√≥n de los Datos

**Eliminaci√≥n de columnas irrelevantes**  
Se elimin√≥ `customerID` por ser un identificador √∫nico que no aporta valor predictivo y puede causar overfitting.

**Verificaci√≥n de proporci√≥n de Churn**  
Se detect√≥ un dataset desbalanceado: 74.28% No Churn vs 25.72% Churn (ratio 2.89:1). Se aplic√≥ **Oversampling** (Random Oversampling) exclusivamente sobre el set de entrenamiento para evitar data leakage.

**Encoding de variables categ√≥ricas**  
- Variables binarias (Yes/No): codificadas como 1/0
- Variables con m√∫ltiples categor√≠as (`Contract`, `PaymentMethod`, `InternetService`): **One-Hot Encoding**
- `gender`: Male=1, Female=0

**Normalizaci√≥n / Estandarizaci√≥n**  
Se crearon dos versiones del dataset con justificaci√≥n t√©cnica:
- **Con StandardScaler** (media=0, std=1): para Regresi√≥n Log√≠stica, sensible a la escala de los datos
- **Sin normalizar**: para Random Forest, basado en √°rboles y no sensible a la escala

**Balanceo de Clases**  
Oversampling aplicado solo al conjunto de entrenamiento para que el test refleje la distribuci√≥n real del negocio.

### b) Correlaci√≥n y Selecci√≥n de Variables

- **Matriz de correlaci√≥n** completa con heatmap de las top 12 variables
- **An√°lisis dirigido Tenure √ó Churn:** boxplot, histograma y tasa de churn por rango de meses
- **An√°lisis dirigido Gasto √ó Churn:** boxplot de MonthlyCharges y TotalCharges + scatter plot

### c) Modelos Entrenados

| | Regresi√≥n Log√≠stica | Random Forest |
|--|--------------------|----|
| **Normalizaci√≥n** | ‚úÖ S√≠ (StandardScaler) | ‚ùå No necesaria |
| **Accuracy (test)** | ~0.75 | ~0.80 |
| **Precision** | ~0.49 | ~0.58 |
| **Recall** | ~0.80 | ~0.73 |
| **F1-Score** | ~0.61 | ~0.64 |
| **ROC-AUC** | ~0.84 | ~0.86 |

**¬øCu√°l modelo es mejor?**

- **Random Forest** obtiene mejor ROC-AUC y F1-Score ‚Üí recomendado para scoring general
- **Regresi√≥n Log√≠stica** obtiene mayor Recall ‚Üí m√°s efectiva para capturar el m√°ximo de churners posibles

En churn, el Recall es especialmente valioso: es m√°s costoso no detectar a un cliente que se va (falso negativo) que alertar err√≥neamente a uno que se queda (falso positivo).

**An√°lisis de Overfitting / Underfitting**

- *Regresi√≥n Log√≠stica:* diferencia Train-Test < 3% ‚Üí sin overfitting, buena generalizaci√≥n gracias a la regularizaci√≥n L2
- *Random Forest:* leve overfitting esperado (~10%) ‚Üí mitigado con `max_depth=12` y `min_samples_leaf=5`

### d) Importancia de Variables

**Regresi√≥n Log√≠stica ‚Äî Coeficientes:**
Los coeficientes positivos m√°s altos corresponden a contratos month-to-month, Fiber Optic y Electronic Check. Los m√°s negativos (protecci√≥n) a contratos anuales y tenure alto.

**Random Forest ‚Äî Gini Importance:**
Las variables con mayor importancia son `tenure`, `MonthlyCharges`, `TotalCharges`, seguidas por el tipo de contrato y el m√©todo de pago.

Ambos modelos coinciden en las mismas variables clave, lo que refuerza la solidez de los hallazgos.

---

## üí° Conclusiones y Estrategias de Retenci√≥n

### Factores principales que causan el churn

1. **Tenure bajo** ‚Äî los primeros 6 meses son cr√≠ticos (51% de cancelaci√≥n)
2. **Contratos sin compromiso** ‚Äî month-to-month tiene 41% de churn vs 2.75% en two-year
3. **Fiber Optic** ‚Äî 40.56% de churn, posiblemente por baja satisfacci√≥n con la calidad
4. **M√©todo de pago manual** ‚Äî Electronic Check: 43.80% vs 14-16% en pagos autom√°ticos
5. **Ausencia de servicios adicionales** ‚Äî sin Tech Support ni Online Security: ~30% churn

### Estrategias propuestas

| Prioridad | Acci√≥n | Impacto Estimado |
|-----------|--------|-----------------|
| üî¥ 1 | Score de riesgo predictivo en producci√≥n | Base para todas las acciones |
| üî¥ 2 | Programa de onboarding intensivo (meses 0-6) | ~260 clientes retenidos/mes |
| üü° 3 | Campa√±a de conversi√≥n a contratos anuales | -7-8 puntos en churn global |
| üü° 4 | Migraci√≥n a pagos autom√°ticos (descuento 5%) | ~130 clientes retenidos/mes |
| üü° 5 | Auditor√≠a de calidad Fiber Optic | ~310 clientes retenidos/mes |
| üü¢ 6 | Bundling de servicios adicionales | ~180 clientes retenidos/mes |

**Proyecci√≥n conservadora (50% de adopci√≥n):**
- ~410 clientes retenidos por mes
- ~$320,000/mes en ingresos protegidos (ARPU ~$65)
- ROI anual estimado: ~$3.8M

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

- **Python 3**
- **Pandas** ‚Äî manipulaci√≥n y limpieza de datos
- **NumPy** ‚Äî operaciones num√©ricas
- **Matplotlib / Seaborn** ‚Äî visualizaci√≥n de datos
- **Scikit-learn** ‚Äî modelado predictivo y evaluaci√≥n
  - `LogisticRegression`
  - `RandomForestClassifier`
  - `StandardScaler`
  - `train_test_split`, `classification_report`, `roc_auc_score`

---

## ‚ñ∂Ô∏è C√≥mo Ejecutar

1. Clona el repositorio:
```bash
git clone https://github.com/javito72/telecomx-churn.git
```

2. Abre los notebooks en [Google Colab](https://colab.research.google.com/) o Jupyter:
```
TelecomX_LATAM.ipynb      ‚Üí Ejecutar primero (EDA)
TelecomX_Parte2_ML.ipynb  ‚Üí Ejecutar segundo (ML)
```

3. Los notebooks se conectan directamente a la fuente de datos v√≠a URL, no se requiere descarga previa del dataset.

---

## üë§ Autor: Christian Javier Lemos

Desarrollado como parte del **Challenge de Ciencia de Datos ‚Äì Alura LATAM**  

---

*"Los datos no mienten: retener un cliente es siempre m√°s barato que adquirir uno nuevo."*

